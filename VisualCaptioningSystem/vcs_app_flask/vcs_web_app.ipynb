{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhKR81U39DmG"},"outputs":[],"source":["!pip install flask-ngrok\n","#2N85BWCuT3u7fwU4SftBtvgG9bZ_7tjq6AEs1np3TWgiCkfuK API key for ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyKDI6viDlMK"},"outputs":[],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1321,"status":"ok","timestamp":1680245130496,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"X1o-oNLw9wX0","outputId":"25427f41-8b98-43c8-c87e-2672479ebc81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]}],"source":["!ngrok authtoken 2N84c3PX2BWS6WKB7xYGRKnwDUb_N6LnBWeHqYeVGQnwZvbt"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4253,"status":"ok","timestamp":1680245145642,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"BQnNQgc8CwaG"},"outputs":[],"source":["from flask import Flask,render_template,request\n","from flask_ngrok import run_with_ngrok\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Model\n","import os\n","from pickle import *\n","import pickle\n","import numpy as np\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, Dropout, LSTM, Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","from keras.utils import to_categorical, plot_model\n","from keras.layers import concatenate\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1581,"status":"ok","timestamp":1680245157087,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"rJLEiFXh3-U0"},"outputs":[],"source":["# extract features from each photo in the directory\n","def extract_feat(filename):\n","    # load the model\n","    model = VGG16()\n","    # re-structure the model\n","    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","    # load the photo\n","    image = load_img(filename, target_size=(224, 224))\n","    # convert the image pixels to a numpy array\n","    image = img_to_array(image)\n","    # reshape data for the model\n","    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","    # prepare the image for the VGG model\n","    image = preprocess_input(image)\n","    # get features\n","    feature = model.predict(image, verbose=0)\n","    return feature\n","\n","# map an integer to a word\n","def word_for_id(integer, tokenizr):\n","    for word, index in tokenizr.word_index.items():\n","        if index == integer:\n","            return word\n","    return None\n"," "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1432,"status":"ok","timestamp":1680245159195,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"gVV8EvRj3_cp"},"outputs":[],"source":["# generate a description for an image\n","def generate_desc(model, tokenizer, photo, max_length):\n","    # seed the generation process\n","    in_text = 'startseq'\n","    # iterate over the whole length of the sequence\n","    for i in range(max_length):\n","        # integer encode input sequence\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        # pad input\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        # predict next word\n","        yhat = model.predict([photo,sequence], verbose=0)\n","        # convert probability to integer\n","        yhat = np.argmax(yhat)\n","        # map integer to word\n","        word = word_for_id(yhat, tokenizer)\n","        # stop if we cannot map the word\n","        if word is None:\n","            break\n","        # append as input for generating the next word\n","        in_text += ' ' + word\n","        # stop if we predict the end of the sequence\n","        if word == 'endseq':\n","            break\n","    return in_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1jlJnCUmciL1PyvYjk8AC2sugSWEHJ5tE"},"executionInfo":{"elapsed":114204,"status":"ok","timestamp":1680169173207,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"wZEWD7sV4SKG","outputId":"63e54566-2326-43cd-8245-af0febd06a98"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["from PIL import Image\n","from keras.models import load_model\n","# load the model\n","modl = load_model('/content/drive/MyDrive/Colab Notebooks/latest20epochs.h5')\n","image_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Flickr8k_Dataset/Flicker8k_Dataset'\n","caption_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Flickr8k_Dataset/Flickr8k_text/Flickr8k.token.txt'\n","obj1=open('/content/drive/MyDrive/Colab Notebooks/new_caption_dict.pkl','rb')\n","new_captions_dict=pickle.load(obj1)\n","obj2=open('/content/drive/MyDrive/Colab Notebooks/train_validate_images.pkl','rb')\n","train_validate_images=pickle.load(obj2)\n","\n","\n","# generate description\n","tokenizr = Tokenizer()\n","tokenizr.fit_on_texts([caption for image, caption in new_captions_dict.items() if image in train_validate_images])\n","max_length = 30\n","\n","for count in range(10):\n","\n","    photo = extract_feat('{}.jpg'.format(image_dataset_path+'/'+train_validate_images[count]))  \n","    im=Image.open('{}.jpg'.format(image_dataset_path+'/'+train_validate_images[count]))\n","    plt.imshow(im)\n","    plt.show()\n","    # generate description\n","    description = generate_desc(modl, tokenizr, photo, max_length)\n","    print(\"Predicted caption -\u003e \", description)\n","    print()\n","    print(\"Actual caption -\u003e \", new_captions_dict[train_validate_images[count]])\n","    print('*********************************************************************')\n","    print()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47836,"status":"ok","timestamp":1680245213811,"user":{"displayName":"Alternate Dimension","userId":"11899559080992280986"},"user_tz":-330},"id":"K7Kmn3-2FhSZ","outputId":"dec63363-b340-4365-c2b0-6c3f31b55af5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467096/553467096 [==============================] - 3s 0us/step\n","Predicted caption -\u003e  startseq man in blue jacket and red hat holds red guitar closed endseq\n"]}],"source":["# load the model\n","modl = load_model('/content/drive/MyDrive/Colab Notebooks/latest20epochs.h5')\n","image_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Flickr8k_Dataset/Flicker8k_Dataset'\n","caption_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Flickr8k_Dataset/Flickr8k_text/Flickr8k.token.txt'\n","obj1=open('/content/drive/MyDrive/Colab Notebooks/new_caption_dict.pkl','rb')\n","new_captions_dict=pickle.load(obj1)\n","obj2=open('/content/drive/MyDrive/Colab Notebooks/train_validate_images.pkl','rb')\n","train_validate_images=pickle.load(obj2)\n","tokenizr = Tokenizer()\n","tokenizr.fit_on_texts([caption for image, caption in new_captions_dict.items() if image in train_validate_images])\n","max_length = 30 \n","photo = extract_feat('/content/drive/MyDrive/Colab Notebooks/Flickr8k_Dataset/Flicker8k_Dataset/1000268201_693b08cb0e.jpg')\n","description = generate_desc(modl, tokenizr, photo, max_length)\n","print(\"Predicted caption -\u003e \", description)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fBFDBfflDSL-"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":[" * Running on http://ae99-35-224-110-178.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:00:19] \"GET / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:00:20] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"]},{"name":"stdout","output_type":"stream","text":["Predicted caption -\u003e  startseq boy in blue shirt is riding bike down the concrete hill endseq\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:00:56] \"POST /after HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:00:56] \"GET /static/file1.jpg HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:01:33] \"POST /after HTTP/1.1\" 200 -\n"]},{"name":"stdout","output_type":"stream","text":["Predicted caption -\u003e  startseq group of people are standing in front of italian company endseq\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [31/Mar/2023 07:01:34] \"GET /static/file1.jpg HTTP/1.1\" 200 -\n"]}],"source":["app=Flask(__name__,template_folder='/content/drive/MyDrive/Colab Notebooks/vcs_app_flask/templates',static_folder='/content/drive/MyDrive/Colab Notebooks/vcs_app_flask/static')\n","app.config['SEND_FILE_MAX_AGE_DEFAULT']=1\n","run_with_ngrok(app)\n","\n","\n","@app.route('/')\n","def index():\n","\n","  return render_template('index.html')\n","  \n","@app.route('/after',methods=['GET','POST'])\n","def after():\n","  imagefile = request.files['file1']\n","  if not imagefile:\n","    return \"Image not submitted!\",404\n","  imagefile.save('/content/drive/MyDrive/Colab Notebooks/vcs_app_flask/static/file1.jpg')\n","  photo = extract_feat('/content/drive/MyDrive/Colab Notebooks/vcs_app_flask/static/file1.jpg')\n","  description = generate_desc(modl, tokenizr, photo, max_length)\n","\n","  print(\"Predicted caption -\u003e \", description)\n","\n","  return render_template('predict.html',caption=description)\n","\n","if __name__==\"__main__\":\n","  app.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbR8s3TeGIef"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOfqIm0oAWNex9T6s/v4YNy","mount_file_id":"1SSmAFRU8_JNeNUoV3TGeR7qFe14xj5CG","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}